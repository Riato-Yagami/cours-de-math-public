% VARIABLES %%%
\def\theme{Statistique à une ou deux variables, représentation et analyse de données}
\def\date{02/12/2023}
%%%%%%%%%%%%%%%

% DEFINITIONS %
\def\ss{série statistique}
\def\ssd{\ss{} à deux variables}
\def\sump{\sum_{i=1}^{p}}
\def\sumN{\sum_{i=1}^{N}}
\def\sN{\frac{1}{N}}
\newcommand{\moy}[1]{
    \overline{#1}
}
\newcommand{\dmoy}[1]{(#1_i-\moy{#1})}
%%%%%%%%%%%%%%

% \setboolean{subsectionInOutline}{true}
% \setboolean{outline}{true}
% \setboolean{demonstration}{false}

% \setboolean{showRef}{false}

\hbox{}
\leconInfo{
    \ilink{5e}
    \ilink{4e}
    \ilink{3e}
    \ilink{2nd}
    \ilink{1re}
    \ilink{Terminale Option Complémentaire}
}
[]
[\ilink{Traitement des données}]
[   
    Offre une méthode rigoureuse pour comprendre et interpréter les
    données.
    Fournit les outils nécessaires pour révéler des tendances, 
    des modèles et des relations au sein des phénomènes observés.
]

% \newsec{2}{seccc}{\PropertyColor}{Propriété zerf}

\section{Série statistique à une variable}

\subsection{Définition}

\df{Série statistique}{
    Une \textbf{\ss}
    est une liste de \textbf{données} ayant une certaine \textbf{valeur};
    mesures d'un \textbf{caractère}
    d'une \textbf{population} et provient généralement d'une étude.
}

\df{Effectif}{
    \begin{itemize}
        \item L'\textbf{effectif} $n_i$ correspond au nombre de fois où une valeur à était obtenue.
        \item L'\textbf{effectif total} $N$ est la taille de la population étudié.
    \end{itemize}
}

\rmk{Représentation \ss}{
    On peut représenter les \ss{} de différentes manières:
    \begin{itemize}
        \item avec une liste
        \item dans un tableau
        \item dans un graphique
    \end{itemize}
}

\subsection{Fréquence}

\df{Fréquence}{
    La \textbf{fréquence} d'une valeur est donnée par l'effectif de la valeur divisée par l'effectif total.
    \begin{align*}
        \textrm{fréquence} &= \frac{\textrm{effectif}}{\textrm{effectif total}}\\
        f_{x_i} &= \frac{n_i}{N}, \forall i \in [|1;n|]
    \end{align*}
}

\pr{Somme des fréquences}{
    La somme de toutes les fréquences d'une \ss{} est égale à 1.
    \begin{equation*}
        \sump f_{x_i} = 1
    \end{equation*}
}

\pr{Fréquence de fréquence}{
    Soient $P$ une population et $A$ et $B$ deux sous-population de $P$,
    avec $B\subset A$.\\
    Si $A$ est de fréquence $x$ dans $P$ 
    et $B$ de fréquence $y$ dans $A$,\\
    alors $B$ est de fréquence $x\times y$ dans $P$.
}

\subsection{Indicateur de position}

\df{Moyenne}{
    La \textbf{moyenne} d'une \ss{}
    est donnée par la somme de ces valeurs divisée par l'effectif total.
    \begin{align*}
        \textrm{moyenne} &= \frac{\textrm{somme des valeurs}}{\textrm{effectif total}}\\
        \moy{x} &= \sN \sumN x_i\\
        &= \sN \sump n_{a_i} x_{a_i} \textrm{ \textbf{moyenne pondérée} avec } \sump n_{a_i} = N
    \end{align*}
}

\pr{Linéarité de la moyenne}{
    Soient $a,b\in\m{R}^2$.\\
    Si la \ss{} $x$ a pour moyenne $\moy{x}$, 
    alors la \ss{} $ax+b$ a pour moyenne $a\moy{x}+b$.
}

\df{Médiane}{
    Dans une \ss,
    la \textbf{médiane} $Me$ est un nombre tel que:
    \begin{itemize}
        \item au moins la moitié des valeurs lui sont supérieures ou égales.
        \item au moins la moitié des valeurs lui sont inférieures ou égales.
    \end{itemize}
}

\rmk{Valeur de la Médiane}{
    \begin{itemize}
        \item Si $N$ est paire, $Me$ est la valeur centrale.
        \item Si $N$ est impaire, on prend la demi-somme des deux valeurs centrale.
    \end{itemize}
}

\df{Quartiles}{
    Dans une \ss,
    on définie 2 \textbf{quartiles}:
    \begin{itemize}
        \item le \textbf{premier quartile} $Q_1$,
        tel que au moins $25\%$ des valuers lui soient inférieures ou égales.
        \item le \textbf{troisième quartile} $Q_3$,
        tel que au moins $75\%$ des valuers lui soient inférieures ou égales.
    \end{itemize}
}

\rmk{Intervalle interquartille}{
    L'intervalle entre les deux quartiles contient la moitié centrale des valeur de la série.
}

\subsection{Indicateur de dispersion}

\df{Etendue}{
    Dans une \ss,
    l'\textbf{étendue} est la différence entre la plus grande valeur et la plus petite valeur.
}

\df{Ecart interquartile}{
    L'\textbf{écart interquartile} $EI$, est la différence entre le troisième et premier quartile.
    \begin{equation*}
        EI(x) = Q_3(x)-Q_1(x)
    \end{equation*}
}

\rmk{Médiane et Ecart interquartile}{
    Plus l'écart interquartile est petit, plus les valeurs centrales de la série se concentrent autour de la médiane.
}

\df{Variance}{
    La \textbf{variance} $V$ est une mesure de la dispersion.
    Elle exprime la moyenne des carrés des écarts à la moyenne.
    \begin{equation*}
        V(x) = \sN \sumN \dmoy{x}^2
    \end{equation*}
}

\thm{de König-Huygens}{
    \begin{equation*}
        V(x) = (\sN \sumN x_i^2) - \moy{x}^2
    \end{equation*}
}

\demo{}{
    \vspace*{-1cm}
    \begin{align*}
        V(x) &= \sN \sumN \dmoy{x}^2\\
        &= \sN \sumN (x_i^2 - 2x_i \moy{x} + \moy{x}^2)\\
        &= \sN \sumN x_i^2 - \frac{2\moy{x}}{N} \sumN x_i  + \sN N \moy{x}^2\\
        &= \sN \sumN x_i^2 - \frac{2\moy{x}}{N} N \moy{x} + \moy{x}^2\\
        &= \sN \sumN x_i^2 - 2\moy{x}^2 + \moy{x}^2\\
        &= \sN \sumN x_i^2 - \moy{x}^2
    \end{align*}
}[\href{https://www.wikiwand.com/fr/Théorème_de_König-Huygens}{Mood et al. (2001, p. 229)}]

\pr{Caractère quadratique de la variance}{
    Soient $a,b\in\m{R}^2$.
    \begin{equation*}
        V(ax+b) = a^2V(x)
    \end{equation*}
}

\df{Ecart type}{
    L'\textbf{écarts type} $\sigma$ est une mesure de la dispersion,
    racine carrée de la variance.
    \begin{equation*}
        \sigma(x) = \sqrt{V(x)}
    \end{equation*}
}

\rmk{Moyenne et écart-type}{
    \begin{itemize}
        \item Plus l'écart-type est grand,
        plus les valeurs sont éloignées de la moyenne.
        \item L'écart-type est homogène au caractère étudié.
    \end{itemize}
}

\subsection{Représentation}

\mthd{Différentes représentations}{
    \begin{itemize}
        \item Histogramme
        \item Diagramme en boîte
    \end{itemize}
}

\section{Série statistique à deux variables}

\subsection{Définition}

\df{Série statistique à deux variables}{
    On considère deux caractères $x$ et $y$,
    de valeurs $x_i$ et $y_i$ pour $i\in\m{[|1;N|]}$,
    observées sur une même population de $N$ individus.\\
    Les couples $(x_i,y_i)$ pour $i\in\m{[|1;N|]}$ forment une \textbf{\ssd}.
}

\rmk{Représentation \ssd}{
    On peut représenter les \ssd{} par un nuage de points
    $M_i(x_i,y_i)$ pour $i\in\m{[|1;N|]}$.
}

\df{Point moyen}{
    Le point $G(\moy{x};\moy{y})$ est appelé \textbf{point moyen}.
}

\subsection{Corrélation linéaire}

\df{Covariance}{
    La \textbf{covariance} mesure la co-variation entre deux \ss $x$ et $y$.
    \begin{align*}
        Cov(x,y) = \sN \sumN \dmoy{x}\dmoy{y}
    \end{align*}
}

\thm{König-Huygens pour la covariance}{
    \begin{equation*}
        Cov(x,y) = (\sN \sumN x_i y_i) - \moy{x} \times \moy{y}
    \end{equation*}
}

\demo{Similaire à la démonstration de König-Huygens pour la variance}{}

\df{Coefficient de corrélation linéaire}{
    Le \textbf{coefficient de corrélation linéaire} $r$,
    mesure la force et la direction de la relation linéaire entre deux variables $x$ et $y$.
    \begin{align*}
        r(x,y) = \frac{Cov(x, y)}{\sigma(x)\sigma(y)}
    \end{align*}
}

\rmk{Interprétation du coefficient de corrélation linéaire}{
    \begin{itemize}
        \item $-1 \leqslant r(x,y) \leqslant 1$
        \item Plus $|r(x,y)|$ augmente plus la corrélation linéaire entre $x$ et $y$ est forte.
        \item Si $r(x,y) \geqslant 0$ alors $x$ et $y$ augmente ensemble.
        \item Si $r(x,y) \leqslant 0$ alors lorsque $x$ augmente $y$ diminue.
    \end{itemize}
}

\subsection{Ajustement affine}

\df{Interpolation et extrapolation}{
    L'\textbf{interpolation} et l'\textbf{extrapolation} sont des méthodes qui consistent à
    estimer une valeur inconnue dans une série statistique.
    \begin{itemize}
        \item pour une interpolation,
        le calcul est réalisé dans le domaine d'étude fourni par les valeurs de la série.
        \item pour une extrapolation,
        le calcul est réalisé en dehors du domaine d'étude.
    \end{itemize}
}

\df{Droite d'ajustement}{
    Dans un nuage de point, on peut construire une droite, appelé \textbf{droite d'ajustement} $y = ax+b$ (ou \textbf{droite de régression}),
    passant « au plus près » des points.
}

\mthd{Des points extrêmes}{
    Droite d'ajustement qui passe par
    le premier point et le dernier point.
    \begin{align*}
        &\lfbrace{
            y_1 &= a x_1 + b\\
            y_N &= a x_N + b
        }\\
        \ialors &\lfbrace{
            b &= y_1 - x_1 \frac{y_n}{x_N-x_1}\\
            a &= \frac{y_n}{x_N-x_1}
        }\\
    \end{align*}
}

\mthd{De Mayer}{
    Droite d'ajustement qui passe par
    les points moyens de deux sous-série obtenue en découpant la \ssd{} en son milieu.
    \begin{align*}
        &\lfbrace{
            \moy{y_1} &= a \moy{x_1} + b\\
            \moy{y_2} &= a \moy{x_2} + b\\
        }
    \end{align*}
}

\mthd{Des moindres carrés}{
    Droite d'ajustement qui
    minimise la somme des carrés des écarts verticals entre
    les valeurs observées et celles prédites par la droite.
    \begin{align*}
        &(a,b) = \operatorname*{argmin}_{(a,b)}\sumN (y_i - (a x_i + b))^2\\
        &\lfbrace{
            a = \frac{Cov(x,y)}{V(x)}\\
            b = \moy{y} - a \moy{x}
        }
    \end{align*}
}

\demo{Méthode Lycée}{
    Soit:
    \begin{align*}
        J(a,b) =& \sumN (y_i - (a x_i + b))^2 = \sumN (y_i - a x_i - b)^2\\
        =& \sumN (\dmoy{y} - a\dmoy{x} - (b - \moy{y} + a\moy{x}))^2\\
        =& \sumN (\dmoy{y} - a\dmoy{x} - c)^2 \avec c = b - \moy{y} + a\moy{x}\\
        =& \sumN (\dmoy{y}^2 + (a\dmoy{x})^2 + c^2 - 2a \dmoy{y} \dmoy{x}\\
        &- 2c\dmoy{y} -2ac\dmoy{x})\\
        \ior \sumN \dmoy{x} =& N\moy{x} - N\moy{x} = 0
        \ialors J(a,b) =& 
        \sumN \dmoy{y}^2 + a^2\dmoy{x}^2 + c^2 - 2a \dmoy{y} \dmoy{x}\\
        =& N(V(Y) + a^2V(X) - 2aCov(X,Y) + c^2)
        \ior &V(Y) + a^2V(X) - 2aCov(X,Y) + c^2\\ 
        =& P(a) + c^2 \textrm{ minimal lorsque } c = 0 = b - \moy{y} + a\moy{x} \et P(a) \textrm{ minimal}
        \ialors b =& \moy{y} - a\moy{x}
        \iet P(a) \textrm{ minimal en } a =& -\frac{\beta}{2\alpha} \textrm{ (polynôme du second degré)}\\
        =& \frac{2Cov(x,y)}{2V(x)} = \frac{Cov(x,y)}{V(x)}
    \end{align*}
}[\href{https://www.bibmath.net/ressources/index.php?action=affiche&quoi=capes/demos/statistiques.html}{Bibmath}]

\newcommand{\partJ}[1]{
    \frac{\partial J}{\partial #1}
}

\demo{Méthode experte}{
    Soit $J(a,b) = \sumN (y_i - (a x_i + b))^2 = \sumN (y_i - a x_i - b)^2$.\\
    Un minimum d'une fonction de plusieurs variables ne peut se produire qu'en un point où les dérivées partielles s'annulent.
    On suppose alors:
    \begin{align*}
        &\lfbrace{
            \partJ{a} &= 0\\
            \partJ{b}&= 0
        }
        \ialors &\lfbrace{
            \partJ{a} &= \sumN -2x_i(y_i - a x_i - b) = 0\\
            \partJ{b} &= \sumN -2(y_i - a x_i - b) = 0
        }
        \ialors &\lfbrace{
            \sumN x_i(y_i - a x_i - b) &= 0\\
            \sumN y_i - a x_i - b &= 0
        }
        \ialors &\lfbrace{
            \sumN x_i y_i - a \sumN x_i^2 - b \sumN x_i &= 0\\
            -Nb + \sumN y_i - a \sumN x_i &= 0
        }
        \ialors &\lfbrace{
            \sumN x_i y_i - a \sumN x_i^2 - b N\moy{x} &= 0\\
            -Nb + N\moy{y} - a N\moy{x} &= 0
        }
        \ialors &\lfbrace{
            \sumN x_i y_i - a \sumN x_i^2 - b N\moy{x} &= 0\\
            - b + \moy{y} - a \moy{x} &= 0
        }
        \ialors &\lfbrace{
            \sumN x_i y_i - a \sumN x_i^2 - b N\moy{x} = 0\\
            b = \moy{y} - a \moy{x}  \textrm{ (on retrouve le résultat admis précédemment)}
        }
        \ialors &\lfbrace{
            \sumN x_i y_i - a \sumN x_i^2 - N\moy{x}(\moy{y} - a \moy{x}) = 0\\
            b = \moy{y} - a \moy{x}
        }
        \ialors &\lfbrace{
            \sumN x_i y_i - N\moy{x}\moy{y} - a (\sumN x_i^2 - N \moy{x}) = 0\\
            b = \moy{y} - a \moy{x}
        }
        \ialors &\lfbrace{
            (\frac{1}{N} \sumN x_i y_i -  \moy{x}\moy{y}) - a (\frac{1}{N} \sumN x_i^2 - \moy{x}) = 0\\
            b = \moy{y} - a \moy{x}
        }
        \ialors &\lfbrace{
            Cov(x,y) - a V(x) = 0 \textrm{ (König-Huygens)}\\
            b = \moy{y} - a \moy{x}
        }
        \ialors &\lfbrace{
            a &= \frac{Cov(x,y)}{V(x)}\\
            b &= \moy{y} - a \moy{x}
        }
    \end{align*}
}[\href{https://www.bibmath.net/dico/index.php?action=affiche&quoi=./r/reglin.html}{Bibmath}]

\rmk{Point moyen et la droite des moindres carrés}{
    Par la définition de la droite des moindres carrés (en particulier les point $b$),
    on a que le point moyen appartient à la droite d'ajustement.
}

\subsection{Ajustement non affine}

\mthd{Changement de variable}{
    Dans certain cas,
    les points du nuage de semblent se répartir autour d'une courbe $y=af(x)+b$ autre qu'une droite.\\
    Il est parfois possible de se ramener à un ajustement affine à l'aide d'un changement de variable $u=f(x)$.
    On peut alors utiliser les méthodes précédentes pour trouver $a$ et $b$.
}


